# Project 2 - Kaggle Challenges with Titanic Survival (Classification) and House Prices (Regression)

Welcome to Project 2! It's time to start EDA and modeling.

**Primary Learning Objectives:**
1. Creating and iteratively refining a regression model and classification model on two popular getting started datasets
2. Using [Kaggle](https://www.kaggle.com/) to practice the modeling process and document findings on Kaggle Kernels
3. Learn from community resources on the platform and collaborate with a physical team

Here are the two competitions you will be joining:

[House prices](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)

[Titanic](https://www.kaggle.com/c/titanic)

Your deliverables are 2 public kernels (one for each competition) on Kaggle per team.

## Set-up

Here are some starting steps:

1. Sign up for an account on [Kaggle](https://www.kaggle.com/)
2. Join the 2 competitions
3. Start looking for teammates (max 4 and min 3 in a team, same members for both competitions, use request to merge team to create teams)
4. Look at tutorials section of each competition to get started. Regression is due next Sunday (6 week) and Classification the Thursday same week (6 week).
5. Inspect the data.
6. Read about the evaluation metrics.
7. Create a new kernel each under the respective competition (data automatically imported) and start collaborating with your team (under sharing setting). Remember to commit often and submit often to iterate on your models.

_NOTE_: At the moment, the new collaborative feature of Kaggle in-browser kernels only support commiting versions without the capability to "pull" to your draft. For a smooth collaborative workflow, we recommend a repo on GitHub Enterprise to collaborate with your team through a commit/push/pull/merge flow.

Some advanced usage of Kaggle kernel via Kaggle API: https://github.com/Kaggle/kaggle-api

## The Modeling Process

1.  retrieve my data from the respective data links on the competitions.
2. Generate my regression/classification model using the training data. We expect that within this process, you'll be making use of:
    - train-test split
    - cross-validation / grid searching for hyperparameters
    - strong exploratory data analysis to question correlation and relationship across predictive variables
    - code that reproducibly and consistently applies feature transformation (such as the preprocessing library)
3. Predict the values for my target column in the test dataset and submit my predictions to Kaggle to see how my model does against unknown data.
    - **Note**: Kaggle expects to see my submissions in a specific format. Check the challenge's page to make sure my are formatting your CSVs correctly!
4. Evaluate models!
    - consider evaluation metrics
    - consider my baseline score
    - how can my model be used for inference?
   

